{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import random\n",
    "import scipy\n",
    "from dit.shannon import mutual_information\n",
    "from dit import *\n",
    "import numpy as np\n",
    "import argparse\n",
    "from model import *\n",
    "from scipy.stats import entropy\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from dit import Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "\t'''\n",
    "\tParses the RandomJump arguments.\n",
    "\t'''\n",
    "\tparser = argparse.ArgumentParser(description=\"Run RandomJump.\")\n",
    "\tparser.add_argument('--name', type=str, default='Marton',\n",
    "\t                    help='Name of the Dataset')\n",
    "\n",
    "\t#For the training of model for jump parameters \n",
    "\tparser.add_argument('--epochs', type=int, default=100000,\n",
    "\t                    help='The number of epoch for jump parameter training')\n",
    "\t\n",
    "\tparser.add_argument('--case_num', type=int, default=100,\n",
    "\t                    help='The number of epoch for jump parameter training')\n",
    "\t\n",
    "\tparser.add_argument('--lr', type=float, default=0.01,\n",
    "\t                    help='The learning rate for jump parameter training')\n",
    "\n",
    "\tparser.add_argument('--dropout', type=float, default=0.6,\n",
    "\t                    help='The dropout for jump parameter training')\n",
    "\n",
    "\tparser.add_argument('--bias', action='store_true', default=True,\n",
    "\t                    help='Boolean specifying bias. Default is True.')\n",
    "\t\n",
    "\tparser.add_argument('--if_print', type=bool, default=True,\n",
    "\t                    help='Decide if print the case configurations')\n",
    "\n",
    "\treturn parser.parse_args(args=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrices_normalize(matrix):\n",
    "    matrix = matrix/matrix.sum(axis=1)[:,None]\n",
    "    return matrix\n",
    "def renorm_the_data(a0, a1, a2, m):\n",
    "    a = [a0, a1, a2, m]\n",
    "    a = np.array(a)\n",
    "    a = np.reshape(a,(1,4))\n",
    "    a = torch.from_numpy(a)\n",
    "    a = a.requires_grad_()\n",
    "    a = a.to(torch.float32)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Cases for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_case():\n",
    "    T_1 = np.random.random((2, 2))\n",
    "    T_1 = matrices_normalize(T_1)\n",
    "\n",
    "    T_2 = np.random.random((2, 2))\n",
    "    T_2 = matrices_normalize(T_2)\n",
    "\n",
    "    X1 = np.random.random((1, 2))\n",
    "    X1 = matrices_normalize(X1)\n",
    "    X2 = np.random.random((1, 2))\n",
    "    X2 = matrices_normalize(X2)\n",
    "\n",
    "    Y1 = np.dot(X1, T_1)\n",
    "    Z1 = np.dot(X1, T_2)\n",
    "\n",
    "    Y2 = np.dot(X2, T_1)\n",
    "    Z2 = np.dot(X2, T_2)\n",
    "\n",
    "    X1 = np.squeeze(X1)\n",
    "    X2 = np.squeeze(X2)\n",
    "    Y1 = np.squeeze(Y1)\n",
    "    Y2 = np.squeeze(Y2)\n",
    "    Z1 = np.squeeze(Z1)\n",
    "    Z2 = np.squeeze(Z2)\n",
    "\n",
    "    return X1, Y1, Z1, X2, Y2, Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_the_case(case_num, T_1, T_2, X1, X2, a):\n",
    "    \n",
    "    print(\"The first transposition matrix:\\n\", T_1)\n",
    "    print(\"The second transposition matrix:\\n\", T_2)\n",
    "    print(\"The first message X1:\\n\", X1)\n",
    "    print(\"The second message X2:\\n\", X2)\n",
    "    print(\"For case\", case_num, \" Loss is smaller than 10^(-4):\", a)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Initialization:\n",
    "\n",
    "1. Two transposition matrices $T_1, T_2$;\n",
    "\n",
    "2. Parameter of gammas: $a0, a1, a2$;\n",
    "\n",
    "3. The sliding parameter: $m$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first transposition matrix:\n",
      " [[0.61038416 0.38961584]\n",
      " [0.10390053 0.89609947]]\n",
      "The second transposition matrix:\n",
      " [[0.51502667 0.48497333]\n",
      " [0.67298263 0.32701737]]\n"
     ]
    }
   ],
   "source": [
    "T_1 = np.random.random((2, 2))\n",
    "T_1 = matrices_normalize(T_1)\n",
    "\n",
    "T_2 = np.random.random((2, 2))\n",
    "T_2 = matrices_normalize(T_2)\n",
    "\n",
    "print(\"The first transposition matrix:\\n\", T_1)\n",
    "print(\"The second transposition matrix:\\n\", T_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the random messages and go through the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first message X1:\n",
      " [0.60471944 0.39528056]\n",
      "Y1 after transpostion T_1:\n",
      " [0.41018103 0.58981897]\n",
      "Z1 after transpostion T_2:\n",
      " [0.57746359 0.42253641]\n",
      "----\n",
      "The second message X2:\n",
      " [0.28768108 0.71231892]\n",
      "Y2 after transpostion T_1:\n",
      " [0.24960629 0.75039371]\n",
      "Z2 after transpostion T_2:\n",
      " [0.62754169 0.37245831]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.random.random((1, 2))\n",
    "X1 = matrices_normalize(X1)\n",
    "X2 = np.random.random((1, 2))\n",
    "X2 = matrices_normalize(X2)\n",
    "\n",
    "Y1 = np.dot(X1, T_1)\n",
    "Z1 = np.dot(X1, T_2)\n",
    "\n",
    "Y2 = np.dot(X2, T_1)\n",
    "Z2 = np.dot(X2, T_2)\n",
    "\n",
    "X1 = np.squeeze(X1)\n",
    "X2 = np.squeeze(X2)\n",
    "Y1 = np.squeeze(Y1)\n",
    "Y2 = np.squeeze(Y2)\n",
    "Z1 = np.squeeze(Z1)\n",
    "Z2 = np.squeeze(Z2)\n",
    "\n",
    "dict_inf = {}\n",
    "dict_inf['X1'] = X1\n",
    "dict_inf['X2'] = X2\n",
    "dict_inf['Y1'] = Y1\n",
    "dict_inf['Y2'] = Y2\n",
    "dict_inf['Z1'] = Z1\n",
    "dict_inf['Z2'] = Z2\n",
    "# dict_input = Distribution(dict_inf)\n",
    "\n",
    "\n",
    "print(\"The first message X1:\\n\", X1)\n",
    "print(\"Y1 after transpostion T_1:\\n\", Y1)\n",
    "print(\"Z1 after transpostion T_2:\\n\", Z1)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "print(\"The second message X2:\\n\", X2)\n",
    "print(\"Y2 after transpostion T_1:\\n\", Y2)\n",
    "print(\"Z2 after transpostion T_2:\\n\", Z2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Formulas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_T1:\n",
      " -0.00795963017512362\n",
      "V1_T2:\n",
      " 0.06824722452032514\n",
      "V2_T12:\n",
      " -0.018377250808475076\n"
     ]
    }
   ],
   "source": [
    "# By Default, set a0, a1, a2 and m as 1\n",
    "a0 = 1\n",
    "a1 = 0.7\n",
    "a2 = 0.5\n",
    "m =0.8\n",
    "V1_T1 = - a0 * m * entropy(X1,Y1) - a0 * (1-m) * entropy(X1,Z1) + max(a1 * entropy(X1,Y1), a2 * entropy(X1,Z1))\n",
    "V1_T2 = - a0 * m * entropy(X2,Y2) - a0 * (1-m) * entropy(X2,Z2) + max(a1 * entropy(X2,Y2), a2 * entropy(X2,Z2))\n",
    "V2_T12 = - a0 * m * entropy(X1*X2,Y1*Y2) - a0 * (1-m) * entropy(X1*X2,Z1*Z2) + max(a1 * entropy(X1*X2,Y1*Y2), a2 * entropy(X1*X2,Z1*Z2))\n",
    "\n",
    "#print(mutual_information(dict_inf, ['X1','X2'],['Y1','Y2']))\n",
    "#How to compute here?\n",
    "\n",
    "print(\"V1_T1:\\n\", V1_T1)\n",
    "print(\"V1_T2:\\n\", V1_T2)\n",
    "print(\"V2_T12:\\n\", V2_T12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (layer4): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Dropout(p=0.6, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "criterion = V2_T12 - V1_T2 - V1_T1\n",
    "model = CNN(args)\n",
    "print(model)\n",
    "learning_rate = args.lr\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first transposition matrix:\n",
      " [[0.61038416 0.38961584]\n",
      " [0.10390053 0.89609947]]\n",
      "The second transposition matrix:\n",
      " [[0.51502667 0.48497333]\n",
      " [0.67298263 0.32701737]]\n",
      "The first message X1:\n",
      " [0.39896997 0.60103003]\n",
      "The second message X2:\n",
      " [0.17870937 0.82129063]\n",
      "For case 2  Loss is smaller than 10^(-4): [1.191271  1.0803992 0.5908054 0.       ]\n",
      "The first transposition matrix:\n",
      " [[0.61038416 0.38961584]\n",
      " [0.10390053 0.89609947]]\n",
      "The second transposition matrix:\n",
      " [[0.51502667 0.48497333]\n",
      " [0.67298263 0.32701737]]\n",
      "The first message X1:\n",
      " [0.46887333 0.53112667]\n",
      "The second message X2:\n",
      " [0.7112106 0.2887894]\n",
      "For case 3  Loss is smaller than 10^(-4): [1.6414692 1.538232  0.8821756 0.       ]\n",
      "The first transposition matrix:\n",
      " [[0.61038416 0.38961584]\n",
      " [0.10390053 0.89609947]]\n",
      "The second transposition matrix:\n",
      " [[0.51502667 0.48497333]\n",
      " [0.67298263 0.32701737]]\n",
      "The first message X1:\n",
      " [0.02158088 0.97841912]\n",
      "The second message X2:\n",
      " [0.36777161 0.63222839]\n",
      "For case 4  Loss is smaller than 10^(-4): [1.5809525 1.538292  0.9625529 0.       ]\n",
      "The first transposition matrix:\n",
      " [[0.61038416 0.38961584]\n",
      " [0.10390053 0.89609947]]\n",
      "The second transposition matrix:\n",
      " [[0.51502667 0.48497333]\n",
      " [0.67298263 0.32701737]]\n",
      "The first message X1:\n",
      " [0.11285294 0.88714706]\n",
      "The second message X2:\n",
      " [0.73433615 0.26566385]\n",
      "For case 6  Loss is smaller than 10^(-4): [0.9000859  0.86492217 0.58856124 0.        ]\n",
      "The first transposition matrix:\n",
      " [[0.61038416 0.38961584]\n",
      " [0.10390053 0.89609947]]\n",
      "The second transposition matrix:\n",
      " [[0.51502667 0.48497333]\n",
      " [0.67298263 0.32701737]]\n",
      "The first message X1:\n",
      " [0.516004 0.483996]\n",
      "The second message X2:\n",
      " [0.00714051 0.99285949]\n",
      "For case 8  Loss is smaller than 10^(-4): [1.6509223  1.5655464  0.88109875 0.        ]\n",
      "The first transposition matrix:\n",
      " [[0.61038416 0.38961584]\n",
      " [0.10390053 0.89609947]]\n",
      "The second transposition matrix:\n",
      " [[0.51502667 0.48497333]\n",
      " [0.67298263 0.32701737]]\n",
      "The first message X1:\n",
      " [0.56105131 0.43894869]\n",
      "The second message X2:\n",
      " [0.60978001 0.39021999]\n",
      "For case 9  Loss is smaller than 10^(-4): [1.6108611  1.3675163  0.85314405 0.        ]\n",
      "The first transposition matrix:\n",
      " [[0.61038416 0.38961584]\n",
      " [0.10390053 0.89609947]]\n",
      "The second transposition matrix:\n",
      " [[0.51502667 0.48497333]\n",
      " [0.67298263 0.32701737]]\n",
      "The first message X1:\n",
      " [0.4787163 0.5212837]\n",
      "The second message X2:\n",
      " [0.68931786 0.31068214]\n",
      "For case 10  Loss is smaller than 10^(-4): [1.635394   1.4308625  0.84651935 0.        ]\n",
      "The first transposition matrix:\n",
      " [[0.61038416 0.38961584]\n",
      " [0.10390053 0.89609947]]\n",
      "The second transposition matrix:\n",
      " [[0.51502667 0.48497333]\n",
      " [0.67298263 0.32701737]]\n",
      "The first message X1:\n",
      " [0.68828785 0.31171215]\n",
      "The second message X2:\n",
      " [0.7519735 0.2480265]\n",
      "For case 11  Loss is smaller than 10^(-4): [1.5323708 1.3998495 0.9679377 0.       ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_96727/1269042417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenorm_the_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-gat/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/Marton/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, args, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-gat/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-gat/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# with Any as TorchScript expects a more precise type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for case_num in range (0,args.case_num):\n",
    "    X1, Y1, Z1, X2, Y2, Z2 = generate_train_case()\n",
    "    for i in range(0,args.epochs):\n",
    "        a = renorm_the_data(a0, a1, a2, m)\n",
    "        a = model(args, a)\n",
    "        a = a.detach().numpy()\n",
    "        a = np.squeeze(a)\n",
    "        a0 = a[0]\n",
    "        a1 = a[1]\n",
    "        a2 = a[2]\n",
    "        m  = a[3]\n",
    "        if a1+a2 > a0 and a0>a1 and a1 >= a2 and a2>=0 and m>=0 and m<1:\n",
    "            V1_T1 = - a0 * m * entropy(X1,Y1) - a0 * (1-m) * entropy(X1,Z1) + max(a1 * entropy(X1,Y1), a2 * entropy(X1,Z1))\n",
    "            V1_T2 = - a0 * m * entropy(X2,Y2) - a0 * (1-m) * entropy(X2,Z2) + max(a1 * entropy(X2,Y2), a2 * entropy(X2,Z2))\n",
    "            V2_T12 = - a0 * m * entropy(X1*X2,Y1*Y2) - a0 * (1-m) * entropy(X1*X2,Z1*Z2) + max(a1 * entropy(X1*X2,Y1*Y2), a2 * entropy(X1*X2,Z1*Z2))\n",
    "            criterion = torch.tensor(V2_T12 - V1_T2 - V1_T1).requires_grad_()\n",
    "            #print(\"For \", i, \" loss is:\", criterion)\n",
    "            train_para_vec(args, a, model, criterion, optimizer)\n",
    "            #print(criterion.item())\n",
    "            if(criterion.item() < 0.0001):\n",
    "                if args.if_print:\n",
    "                    print_the_case(case_num, T_1, T_2, X1, X2, a)\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            a = renorm_the_data(a0, a1, a2, m)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "475809901116d6201fd217492a2b7f3440190c405255ceb03725fe62f2025872"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pytorch-gat': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
